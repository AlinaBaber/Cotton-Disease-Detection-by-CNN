{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Cottondiseasedetectiontestapi.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Fexsv5Vm0CjH"},"source":["## Import Library "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AN2TAU360DgE","executionInfo":{"status":"ok","timestamp":1636110899201,"user_tz":-300,"elapsed":30611,"user":{"displayName":"Alina Baber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjUgi6JqEc9C1vG1gVI7wEF-7eOnos1u859PjcqZg=s64","userId":"07016951716642667333"}},"outputId":"cfd3894e-4ed0-4a68-b7b5-c2c37980a270"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"_LIPNOVe0CjO"},"source":["import os\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UiDDHMP50CjP"},"source":["train_data_path = \"/content/drive/MyDrive/enhancedretinopathy-dataset\"\n","validation_data_path = \"/content/drive/MyDrive/cottondataset/val\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"897Lt5p30CjQ"},"source":["Load a dataset from the google drive.In data set there are three floder one is train set and another is test set.In all three floder there four sub floder is there. 1.diseased cotton leaf 2.diseased cotton plant 3.fresh cotton leaf 4.fresh cotton plant"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Blm_ND2T0CjQ","executionInfo":{"status":"ok","timestamp":1636111833399,"user_tz":-300,"elapsed":801,"user":{"displayName":"Alina Baber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjUgi6JqEc9C1vG1gVI7wEF-7eOnos1u859PjcqZg=s64","userId":"07016951716642667333"}},"outputId":"a21318b6-1198-4224-8c4d-27eb80684925"},"source":["train_datagen = ImageDataGenerator(rescale=1./255,\n","                                      rotation_range=40,\n","                                      width_shift_range=0.2,\n","                                      height_shift_range=0.2,\n","                                      shear_range=0.2,\n","                                      zoom_range=0.2,\n","                                      horizontal_flip=True,\n","                                      fill_mode='nearest')\n"," \n","training_data = train_datagen.flow_from_directory(train_data_path, \n","                                      target_size=(150, 150),\n","                                      batch_size=32,\n","                                      class_mode='binary') "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 0 images belonging to 2 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"eG1ltR8Q0CjR"},"source":["for i in os.listdir(\"/content/drive/MyDrive/cottondataset/train/\"):\n","    print(str(len(os.listdir(\"/content/drive/MyDrive/cottondataset/train/\"+i))) +\" \"+ i +\" images\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QE8Tbxnz0CjR"},"source":["valid_datagen = ImageDataGenerator(rescale=1./255)\n","\n","valid_data = valid_datagen.flow_from_directory(validation_data_path,\n","                                  target_size=(150,150),\n","                                  batch_size=32,\n","                                  class_mode='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ZRRFwen0CjS"},"source":["for i in os.listdir(\"/content/drive/MyDrive/cottondataset/val/\"):\n","    print(str(len(os.listdir(\"/content/drive/MyDrive/cottondataset/val/\"+i))) +\" \"+ i +\" images\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yaTmpkOZ0CjS"},"source":["model_path = '/content/drive/MyDrive/cottondataset/model/test.h5'\n","checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CxIk2bDD0CjS"},"source":["model = keras.models.Sequential([\n","                                    keras.layers.Conv2D(filters=32, kernel_size=3, input_shape=[150, 150, 3]),\n","                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n","                                    keras.layers.Conv2D(filters=64, kernel_size=3),\n","                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n","                                    keras.layers.Conv2D(filters=128, kernel_size=3),\n","                                    keras.layers.MaxPooling2D(pool_size=(2,2)),                                    \n","                                    keras.layers.Conv2D(filters=256, kernel_size=3),\n","                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n"," \n","                                    keras.layers.Dropout(0.5),                                                                        \n","                                    keras.layers.Flatten(), \n","                                    keras.layers.Dense(units=128, activation='relu'), \n","                                    keras.layers.Dropout(0.1),                                    \n","                                    keras.layers.Dense(units=256, activation='relu'),                                    \n","                                    keras.layers.Dropout(0.25),                                    \n","                                    keras.layers.Dense(units=4, activation='softmax') \n","])\n"," \n"," \n","model.compile(optimizer = Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A9QulZ210CjT"},"source":["history = model.fit(training_data, \n","                          epochs=100, \n","                          verbose=1, \n","                          validation_data= valid_data,\n","                          callbacks=callbacks_list) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HVAICOg80CjT"},"source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xlUzs1RpgpbJ"},"source":["!pip install tensorflow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvWyVbyd0CjU"},"source":["from tensorflow import lite\n","import tensorflow as tf\n","\n","models = tf.keras.models.load_model('/content/drive/MyDrive/cottondataset/model/test.h5')\n","converter= lite.TFLiteConverter.from_keras_model(models )\n","print(converter)\n","model = converter.convert()\n","file = open('/content/drive/MyDrive/cottondataset/model/model.tflite' , 'wb').write(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QjvJxJI40CjU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u80L_4Se0CjU"},"source":["# load and evaluate a saved model\n","import numpy as np\n","from keras.models import load_model\n","from keras.preprocessing import image\n","# load model\n","model = load_model('/content/drive/MyDrive/cottondataset/model/test.h5')\n","# summarize model.\n","#model.summary()\n","# load dataset\n","Image_test='/content/drive/MyDrive/cottondataset/test/diseased cotton leaf/dis_leaf (124).jpg'\n","image1 = image.load_img(Image_test, target_size=(150, 150))\n","#image1\n","input_arr = image.img_to_array(image1)\n","input_arr = np.array([input_arr])  # Convert single image to a batch.\n","input_arr\n","predictions1 = model.predict(input_arr)\n","print(predictions1)\n","probabilities1 = model.predict_proba(input_arr)\n","print(probabilities1)\n","\n","Image_test='/content/drive/MyDrive/cottondataset/test/diseased cotton plant/dd (41).jpg'\n","image2 = image.load_img(Image_test, target_size=(150, 150))\n","#image1\n","input_arr = image.img_to_array(image2)\n","input_arr = np.array([input_arr])  # Convert single image to a batch.\n","#input_arr\n","predictions2 = model.predict(input_arr)\n","print(predictions2)\n","probabilities2 = model.predict_proba(input_arr)\n","print(probabilities2)\n","\n","Image_test='/content/drive/MyDrive/cottondataset/test/fresh cotton leaf/d (378).jpg'\n","image3 = image.load_img(Image_test, target_size=(150, 150))\n","#image1\n","input_arr = image.img_to_array(image3)\n","input_arr = np.array([input_arr])  # Convert single image to a batch.\n","#input_arr\n","predictions3 = model.predict(input_arr)\n","print(predictions3)\n","probabilities3 = model.predict_proba(input_arr)\n","print(probabilities3)\n","\n","Image_test='/content/drive/MyDrive/cottondataset/test/fresh cotton plant/dsd (600).jpg'\n","image4 = image.load_img(Image_test, target_size=(150, 150))\n","#image1\n","input_arr = image.img_to_array(image4)\n","input_arr = np.array([input_arr])  # Convert single image to a batch.\n","#input_arr\n","predictions4 = model.predict(input_arr)\n","print(predictions4)\n","probabilities4 = model.predict(input_arr)\n","print(probabilities4)\n","\n","predictionsclasses=['diseased cotton leaf','diseased cotton plant','fresh cotton leaf','fresh cotton plant']\n","probabilitiestest=list(probabilities3)\n","testprob = max(probabilitiestest)\n","print(testprob.tolist())\n","max_value = max(testprob)\n","print(max_value)\n","for i in range(len( testprob)):\n","  if testprob[i] == max_value:\n","    max_index =i\n","print(predictionsclasses[max_index])"],"execution_count":null,"outputs":[]}]}